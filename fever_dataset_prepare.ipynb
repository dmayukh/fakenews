{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "referenced-debut",
   "metadata": {},
   "source": [
    "#### The Data\n",
    "The test data is in 'paper_test.jsonl'\n",
    "\n",
    "The data is copied from the directory in the image to 'data/data/'\n",
    "\n",
    "The annotations are available in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "killing-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mpaper_dev.jsonl\u001b[0m*   \u001b[01;32mshared_task_dev.jsonl\u001b[0m*   \u001b[01;32mtrain.jsonl\u001b[0m*\n",
      "\u001b[01;32mpaper_test.jsonl\u001b[0m*  \u001b[01;32mshared_task_test.jsonl\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "ls data/data/fever-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "available-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999 data/data/fever-data/paper_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/data/fever-data/paper_test.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "constitutional-passport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": 113501, \"verifiable\": \"NOT VERIFIABLE\", \"label\": \"NOT ENOUGH INFO\", \"claim\": \"Grease had bad reviews.\", \"evidence\": [[[133128, null, null, null]]]}\n",
      "{\"id\": 163803, \"verifiable\": \"VERIFIABLE\", \"label\": \"SUPPORTS\", \"claim\": \"Ukrainian Soviet Socialist Republic was a founding participant of the UN.\", \"evidence\": [[[296950, 288668, \"Ukrainian_Soviet_Socialist_Republic\", 7]], [[298602, 290067, \"Ukrainian_Soviet_Socialist_Republic\", 7], [298602, 290067, \"United_Nations\", 0]], [[300696, 291816, \"Ukrainian_Soviet_Socialist_Republic\", 7]], [[344347, 327887, \"Ukrainian_Soviet_Socialist_Republic\", 7]], [[344994, 328433, \"Ukrainian_Soviet_Socialist_Republic\", 7]], [[344997, 328435, \"Ukrainian_Soviet_Socialist_Republic\", 7]]]}\n"
     ]
    }
   ],
   "source": [
    "!head -2 data/data/fever-data/paper_test.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-south",
   "metadata": {},
   "source": [
    "Load the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "architectural-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from drqa import retriever\n",
    "tdidf_npz_file = 'data/data/index/fever-tfidf-ngram=2-hash=16777216-tokenizer=simple.npz'\n",
    "ranker = retriever.get_class('tfidf')(tfidf_path=tdidf_npz_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "infinite-machine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<drqa.retriever.tfidf_doc_ranker.TfidfDocRanker at 0x7f63d9908390>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-script",
   "metadata": {},
   "source": [
    "Format the data, sample randomly for not enough info class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "starting-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def prepare_dataset(split, k=5):\n",
    "    fever_root = 'data/'\n",
    "    working_dir = 'working/data/'\n",
    "    print(\"Saving prepared dataset to {}\".format(\"training/{0}.ns.pages.p{1}.jsonl\".format(split,k)))\n",
    "    with open(fever_root + \"data/fever-data/{0}.jsonl\".format(split),\"r\") as f_in:\n",
    "        with open(working_dir + \"training/{0}.ns.pages.p{1}.jsonl\".format(split,k),\"w+\") as f_out:\n",
    "            for line in tqdm(f_in.readlines()):\n",
    "                line = json.loads(line)\n",
    "                if line[\"label\"] == \"NOT ENOUGH INFO\":\n",
    "                        doc_names, doc_scores = ranker.closest_docs(line['claim'], k)\n",
    "                        pp = list(doc_names)\n",
    "\n",
    "                        for idx,evidence_group in enumerate(line['evidence']):\n",
    "                            for evidence in evidence_group:\n",
    "                                if idx<len(pp):\n",
    "                                    evidence[2] = pp[idx]\n",
    "                                    evidence[3] = -1\n",
    "                \n",
    "                f_out.write(json.dumps(line) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "existing-import",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prepared dataset to training/paper_test.ns.pages.p5.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [02:36<00:00, 63.69it/s] \n"
     ]
    }
   ],
   "source": [
    "!rm -rf training/test.ns.pages.p5.jsonl\n",
    "prepare_dataset('paper_test', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "suitable-serial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_dev.ns.pages.p5.jsonl   train.ns.pages.p5.jsonl\n",
      "paper_test.ns.pages.p5.jsonl  train.pages.p5.jsonl\n"
     ]
    }
   ],
   "source": [
    "ls working/data/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "interracial-projection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999 working/data/training/paper_test.ns.pages.p5.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc -l working/data/training/paper_test.ns.pages.p5.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "romance-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "class LabelSchema:\n",
    "    def __init__(self,labels):\n",
    "        self.labels = {self.preprocess(val):idx for idx,val in enumerate(labels)}\n",
    "        self.idx = {idx:self.preprocess(val) for idx,val in enumerate(labels)}\n",
    "\n",
    "    def get_id(self,label):\n",
    "        if self.preprocess(label) in self.labels:\n",
    "            return self.labels[self.preprocess(label)]\n",
    "        return None\n",
    "\n",
    "    def preprocess(self,item):\n",
    "        return item.lower()\n",
    "\n",
    "class FEVERLabelSchema(LabelSchema):\n",
    "    def __init__(self):\n",
    "        super().__init__([\"supports\", \"refutes\", \"not enough info\"])\n",
    "\n",
    "def nltk_tokenizer(text):\n",
    "    return \" \".join(word_tokenize(text))\n",
    "\n",
    "class training_line_formatter():\n",
    "    def __init__(self):\n",
    "        self.tokenize = nltk_tokenizer\n",
    "        \n",
    "    def format(self, lines):\n",
    "        formatted = []\n",
    "        for line in tqdm(lines):\n",
    "            fl = self.format_line(line)\n",
    "            if fl is not None:\n",
    "                if isinstance(fl,list):\n",
    "                    formatted.extend(fl)\n",
    "                else:\n",
    "                    formatted.append(fl)\n",
    "        return formatted\n",
    "\n",
    "    def format_line(self, line):\n",
    "        label_schema = FEVERLabelSchema()\n",
    "        # get the label, i.e. SUPPORTS etc.\n",
    "        annotation = line[\"label\"]\n",
    "        if annotation is None:\n",
    "            annotation = line[\"verifiable\"]\n",
    "        pages = []\n",
    "        # did we get the closest sentences to the claim text? is this the sentence or the line number from the doc text?\n",
    "        if 'predicted_sentences' in line:\n",
    "            pages.extend([(ev[0], ev[1]) for ev in line[\"predicted_sentences\"]])\n",
    "        elif 'predicted_pages' in line:\n",
    "            pages.extend([(ev[0], -1) for ev in line[\"predicted_pages\"]])\n",
    "        else:\n",
    "            # these are the human annotated evidence available in the original training file\n",
    "            for evidence_group in line[\"evidence\"]:\n",
    "                pages.extend([(ev[2], ev[3]) for ev in evidence_group])\n",
    "\n",
    "        return {\"claim\": self.tokenize(line[\"claim\"]), \"evidence\": pages, \"label\": label_schema.get_id(annotation),\n",
    "                \"label_text\": annotation}\n",
    "    \n",
    "class Reader:\n",
    "    def __init__(self,encoding=\"utf-8\"):\n",
    "        self.enc = encoding\n",
    "\n",
    "    def read(self,file):\n",
    "        with open(file,\"r\",encoding = self.enc) as f:\n",
    "            return self.process(f)\n",
    "\n",
    "    def process(self,f):\n",
    "        pass\n",
    "\n",
    "class JSONLineReader(Reader):\n",
    "    def process(self,fp):\n",
    "        data = []\n",
    "        for line in tqdm(fp.readlines()):\n",
    "            data.append(json.loads(line.strip()))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adequate-handling",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "boxed-desert",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:00<00:00, 180319.31it/s]\n",
      "100%|██████████| 9999/9999 [00:01<00:00, 8289.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'claim': 'Grease had bad reviews .',\n",
       "  'evidence': [('Grease_gun_-LRB-tool-RRB-', -1)],\n",
       "  'label': 2,\n",
       "  'label_text': 'NOT ENOUGH INFO'},\n",
       " {'claim': 'Ukrainian Soviet Socialist Republic was a founding participant of the UN .',\n",
       "  'evidence': [('Ukrainian_Soviet_Socialist_Republic', 7),\n",
       "   ('Ukrainian_Soviet_Socialist_Republic', 7),\n",
       "   ('United_Nations', 0),\n",
       "   ('Ukrainian_Soviet_Socialist_Republic', 7),\n",
       "   ('Ukrainian_Soviet_Socialist_Republic', 7),\n",
       "   ('Ukrainian_Soviet_Socialist_Republic', 7),\n",
       "   ('Ukrainian_Soviet_Socialist_Republic', 7)],\n",
       "  'label': 0,\n",
       "  'label_text': 'SUPPORTS'},\n",
       " {'claim': '2 Hearts is a musical composition by Minogue .',\n",
       "  'evidence': [('2_Hearts_-LRB-Kylie_Minogue_song-RRB-', 0),\n",
       "   ('2_Hearts_-LRB-Kylie_Minogue_song-RRB-', 0),\n",
       "   ('2_Hearts_-LRB-Kylie_Minogue_song-RRB-', 0),\n",
       "   ('2_Hearts_-LRB-Kylie_Minogue_song-RRB-', 0)],\n",
       "  'label': 0,\n",
       "  'label_text': 'SUPPORTS'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "jlr = JSONLineReader()\n",
    "split = 'paper_test'\n",
    "working_dir = 'working/data/'\n",
    "k = 5\n",
    "test_data_file = working_dir + \"training/{0}.ns.pages.p{1}.jsonl\".format(split, k)\n",
    "test_data = jlr.read(test_data_file)\n",
    "\n",
    "formatter = training_line_formatter()\n",
    "formatted_test_data = formatter.format(test_data)\n",
    "\n",
    "test_data_formatted = []\n",
    "test_data_formatted.extend(filter(lambda record: record is not None, formatted_test_data))\n",
    "test_data_formatted[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-instrumentation",
   "metadata": {},
   "source": [
    "##### PIPELINE setting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "classified-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def prepare_dataset_test(split, k=5):\n",
    "    fever_root = 'data/'\n",
    "    working_dir = 'working/data/'\n",
    "    print(\"Saving prepared dataset to {}\".format(\"training/{0}.ns.pages.p{1}.jsonl\".format(split,k)))\n",
    "    with open(fever_root + \"data/fever-data/{0}.jsonl\".format(split),\"r\") as f_in:\n",
    "        with open(working_dir + \"training/{0}_pipeline.ns.pages.p{1}.jsonl\".format(split,k),\"w+\") as f_out:\n",
    "            for line in tqdm(f_in.readlines()):\n",
    "                line = json.loads(line)\n",
    "                \n",
    "                doc_names, doc_scores = ranker.closest_docs(line['claim'], k)\n",
    "                pp = list(doc_names)\n",
    "\n",
    "                for idx,evidence_group in enumerate(line['evidence']):\n",
    "                    for evidence in evidence_group:\n",
    "                        if idx<len(pp):\n",
    "                            evidence[2] = pp[idx]\n",
    "                            if line[\"label\"] == \"NOT ENOUGH INFO\":\n",
    "                                evidence[3] = -1\n",
    "                            else:\n",
    "                                evidence[3] = -2\n",
    "                        else:\n",
    "                            evidence[2] = pp[-1] #repeat the last one\n",
    "                            evidence[3] = -2\n",
    "                if len(pp) > idx:\n",
    "                    for i in range(len(pp)-1-idx):\n",
    "                        ev = [[-1, None, pp[i], -2]]\n",
    "                        evidence_group.extend(ev)\n",
    "                #setting evidence of all samples to -1 so that during dataset preparation, we sample lines from the document as per nearest match DrQA\n",
    "                f_out.write(json.dumps(line) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "planned-treasure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc: working/data/training/paper_test_pipeline.ns.pages.p5.jsonl: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -rf working/data/training/paper_test_pipeline.ns.pages.p5.jsonl\n",
    "!wc -l working/data/training/paper_test_pipeline.ns.pages.p5.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "artificial-resolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prepared dataset to training/paper_test.ns.pages.p5.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [07:16<00:00, 22.90it/s]\n"
     ]
    }
   ],
   "source": [
    "!rm -rf training/paper_test_pipeline.ns.pages.p5.jsonl\n",
    "prepare_dataset_test('paper_test', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "median-assignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": 113501, \"verifiable\": \"NOT VERIFIABLE\", \"label\": \"NOT ENOUGH INFO\", \"claim\": \"Grease had bad reviews.\", \"evidence\": [[[133128, null, \"Grease_gun_-LRB-tool-RRB-\", -1], [-1, null, \"Grease_gun_-LRB-tool-RRB-\", -2], [-1, null, \"Nasal_sebum\", -2], [-1, null, \"Grease\", -2], [-1, null, \"Thermal_interface_material\", -2]]]}\n",
      "{\"id\": 163803, \"verifiable\": \"VERIFIABLE\", \"label\": \"SUPPORTS\", \"claim\": \"Ukrainian Soviet Socialist Republic was a founding participant of the UN.\", \"evidence\": [[[296950, 288668, \"Emblem_of_the_Ukrainian_Soviet_Socialist_Republic\", -2]], [[298602, 290067, \"Flag_of_the_Moldavian_Autonomous_Soviet_Socialist_Republic\", -2], [298602, 290067, \"Flag_of_the_Moldavian_Autonomous_Soviet_Socialist_Republic\", -2]], [[300696, 291816, \"Ukrainian_Republic\", -2]], [[344347, 327887, \"List_of_Presidents_of_Ukraine\", -2]], [[344994, 328433, \"United_Nations_General_Assembly_Resolution_377\", -2]], [[344997, 328435, \"United_Nations_General_Assembly_Resolution_377\", -2]]]}\n",
      "{\"id\": 70041, \"verifiable\": \"VERIFIABLE\", \"label\": \"SUPPORTS\", \"claim\": \"2 Hearts is a musical composition by Minogue.\", \"evidence\": [[[225394, 230056, \"2_Hearts_-LRB-Kylie_Minogue_song-RRB-\", -2]], [[317953, 306972, \"Kylie_Minogue_singles_discography\", -2]], [[319638, 308345, \"Kylie_Minogue\", -2]], [[319643, 308348, \"X_-LRB-Kylie_Minogue_album-RRB-\", -2], [-1, null, \"2_Hearts_-LRB-Kylie_Minogue_song-RRB-\", -2]]]}\n",
      "{\"id\": 202314, \"verifiable\": \"VERIFIABLE\", \"label\": \"REFUTES\", \"claim\": \"The New Jersey Turnpike has zero shoulders.\", \"evidence\": [[[238335, 240393, \"Interstate_95_in_New_Jersey\", -2], [-1, null, \"Interstate_95_in_New_Jersey\", -2], [-1, null, \"List_of_turnpikes_in_New_Jersey\", -2], [-1, null, \"New_Jersey_Turnpike\", -2], [-1, null, \"Newark_Bay_Bridge\", -2]]]}\n",
      "{\"id\": 57085, \"verifiable\": \"NOT VERIFIABLE\", \"label\": \"NOT ENOUGH INFO\", \"claim\": \"Legendary Entertainment is the owner of Wanda Cinemas.\", \"evidence\": [[[178035, null, \"Wanda_Cinemas\", -1], [182093, null, \"Wanda_Cinemas\", -1], [314120, null, \"Wanda_Cinemas\", -1], [314126, null, \"Wanda_Cinemas\", -1], [314131, null, \"Wanda_Cinemas\", -1], [-1, null, \"Wanda_Cinemas\", -2], [-1, null, \"Wanda_Group\", -2], [-1, null, \"Legendary_Entertainment\", -2], [-1, null, \"List_of_shows_produced_by_Legendary_Television\", -2]]]}\n",
      "{\"id\": 6032, \"verifiable\": \"VERIFIABLE\", \"label\": \"REFUTES\", \"claim\": \"Aruba is the only ABC Island.\", \"evidence\": [[[22769, 28071, \"Frans_Figaroa\", -2]], [[22769, 28072, \"Constitution_of_Aruba\", -2], [-1, null, \"Frans_Figaroa\", -2], [-1, null, \"Constitution_of_Aruba\", -2], [-1, null, \"Outline_of_Aruba\", -2]]]}\n",
      "{\"id\": 176630, \"verifiable\": \"NOT VERIFIABLE\", \"label\": \"NOT ENOUGH INFO\", \"claim\": \"Great white sharks do not prefer dolphins as prey.\", \"evidence\": [[[204612, null, \"Great_white_shark\", -1], [-1, null, \"Great_white_shark\", -2], [-1, null, \"Andre_Hartman\", -2], [-1, null, \"Gansbaai\", -2], [-1, null, \"White_Shark_Cafe\\u0301\", -2]]]}\n",
      "{\"id\": 130048, \"verifiable\": \"VERIFIABLE\", \"label\": \"REFUTES\", \"claim\": \"Burbank, California has always been completely void of industry.\", \"evidence\": [[[152264, 167060, \"Burbank_City_Hall\", -2], [-1, null, \"Burbank_City_Hall\", -2], [-1, null, \"Burbank_-LRB-surname-RRB-\", -2], [-1, null, \"Maximum_II\", -2], [-1, null, \"Fort_Mangochi\", -2]]]}\n",
      "{\"id\": 100046, \"verifiable\": \"NOT VERIFIABLE\", \"label\": \"NOT ENOUGH INFO\", \"claim\": \"The Guthrie Theater's second building began operating in 1963.\", \"evidence\": [[[117690, null, \"Joe_Dowling\", -1], [-1, null, \"Joe_Dowling\", -2], [-1, null, \"Guthrie_Theater_production_history\", -2], [-1, null, \"Guthrie_Theater\", -2], [-1, null, \"Gold_Medal_Park\", -2]]]}\n",
      "{\"id\": 204575, \"verifiable\": \"VERIFIABLE\", \"label\": \"REFUTES\", \"claim\": \"Commodore is ranked above a rear admiral.\", \"evidence\": [[[241594, 243126, \"List_of_Supply_Officers_in_the_Royal_Navy_who_have_reached_flag_rank\", -2]], [[241594, 243127, \"Commodore_admiral\", -2], [241594, 243127, \"Commodore_admiral\", -2], [-1, null, \"List_of_Supply_Officers_in_the_Royal_Navy_who_have_reached_flag_rank\", -2], [-1, null, \"Commodore_admiral\", -2], [-1, null, \"Rear_admiral\", -2]]]}\n"
     ]
    }
   ],
   "source": [
    "!head working/data/training/paper_test_pipeline.ns.pages.p5.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "contemporary-front",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": 113501, \"verifiable\": \"NOT VERIFIABLE\", \"label\": \"NOT ENOUGH INFO\", \"claim\": \"Grease had bad reviews.\", \"evidence\": [[[133128, null, null, null]]]}\n",
      "{\"id\": 163803, \"verifiable\": \"VERIFIABLE\", \"label\": \"SUPPORTS\", \"claim\": \"Ukrainian Soviet Socialist Republic was a founding participant of the UN.\", \"evidence\": [[[296950, 288668, \"Ukrainian_Soviet_Socialist_Republic\", 7]], [[298602, 290067, \"Ukrainian_Soviet_Socialist_Republic\", 7], [298602, 290067, \"United_Nations\", 0]], [[300696, 291816, \"Ukrainian_Soviet_Socialist_Republic\", 7]], [[344347, 327887, \"Ukrainian_Soviet_Socialist_Republic\", 7]], [[344994, 328433, \"Ukrainian_Soviet_Socialist_Republic\", 7]], [[344997, 328435, \"Ukrainian_Soviet_Socialist_Republic\", 7]]]}\n",
      "{\"id\": 70041, \"verifiable\": \"VERIFIABLE\", \"label\": \"SUPPORTS\", \"claim\": \"2 Hearts is a musical composition by Minogue.\", \"evidence\": [[[225394, 230056, \"2_Hearts_-LRB-Kylie_Minogue_song-RRB-\", 0]], [[317953, 306972, \"2_Hearts_-LRB-Kylie_Minogue_song-RRB-\", 0]], [[319638, 308345, \"2_Hearts_-LRB-Kylie_Minogue_song-RRB-\", 0]], [[319643, 308348, \"2_Hearts_-LRB-Kylie_Minogue_song-RRB-\", 0]]]}\n",
      "{\"id\": 202314, \"verifiable\": \"VERIFIABLE\", \"label\": \"REFUTES\", \"claim\": \"The New Jersey Turnpike has zero shoulders.\", \"evidence\": [[[238335, 240393, \"New_Jersey_Turnpike\", 15]]]}\n",
      "{\"id\": 57085, \"verifiable\": \"NOT VERIFIABLE\", \"label\": \"NOT ENOUGH INFO\", \"claim\": \"Legendary Entertainment is the owner of Wanda Cinemas.\", \"evidence\": [[[178035, null, null, null], [182093, null, null, null], [314120, null, null, null], [314126, null, null, null], [314131, null, null, null]]]}\n",
      "{\"id\": 6032, \"verifiable\": \"VERIFIABLE\", \"label\": \"REFUTES\", \"claim\": \"Aruba is the only ABC Island.\", \"evidence\": [[[22769, 28071, \"ABC_islands_-LRB-Lesser_Antilles-RRB-\", 0]], [[22769, 28072, \"ABC_islands_-LRB-Lesser_Antilles-RRB-\", 1]]]}\n",
      "{\"id\": 176630, \"verifiable\": \"NOT VERIFIABLE\", \"label\": \"NOT ENOUGH INFO\", \"claim\": \"Great white sharks do not prefer dolphins as prey.\", \"evidence\": [[[204612, null, null, null]]]}\n",
      "{\"id\": 130048, \"verifiable\": \"VERIFIABLE\", \"label\": \"REFUTES\", \"claim\": \"Burbank, California has always been completely void of industry.\", \"evidence\": [[[152264, 167060, \"Burbank,_California\", 7]]]}\n",
      "{\"id\": 100046, \"verifiable\": \"NOT VERIFIABLE\", \"label\": \"NOT ENOUGH INFO\", \"claim\": \"The Guthrie Theater's second building began operating in 1963.\", \"evidence\": [[[117690, null, null, null]]]}\n",
      "{\"id\": 204575, \"verifiable\": \"VERIFIABLE\", \"label\": \"REFUTES\", \"claim\": \"Commodore is ranked above a rear admiral.\", \"evidence\": [[[241594, 243126, \"Commodore_-LRB-rank-RRB-\", 0]], [[241594, 243127, \"Commodore_-LRB-rank-RRB-\", 9], [241594, 243127, \"Rear_admiral\", 0]]]}\n"
     ]
    }
   ],
   "source": [
    "!head data/data/fever-data/paper_test.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-elite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-minnesota",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "local-michael",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/9999 [00:00<09:15, 17.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prepared dataset to training/paper_test.ns.pages.p5.jsonl\n",
      "line...\n",
      "{'id': 113501, 'verifiable': 'NOT VERIFIABLE', 'label': 'NOT ENOUGH INFO', 'claim': 'Grease had bad reviews.', 'evidence': [[[133128, None, None, None]]]}\n",
      "....\n",
      "docs....\n",
      "['Grease_gun_-LRB-tool-RRB-', 'Nasal_sebum', 'Grease', 'Thermal_interface_material', 'Grease_trap']\n",
      "LENGTH = 1\n",
      "for idx and evidence ....... 0\n",
      "0 [[133128, None, None, None]]\n",
      ">>>>>\n",
      "0 [[133128, None, 'Grease_gun_-LRB-tool-RRB-', -1]]\n",
      "IDX =  0 5\n",
      "************* FINAL LINE *********\n",
      "{'id': 113501, 'verifiable': 'NOT VERIFIABLE', 'label': 'NOT ENOUGH INFO', 'claim': 'Grease had bad reviews.', 'evidence': [[[133128, None, 'Grease_gun_-LRB-tool-RRB-', -1], [-1, None, 'Grease_gun_-LRB-tool-RRB-', -1], [-1, None, 'Nasal_sebum', -1], [-1, None, 'Grease', -1], [-1, None, 'Thermal_interface_material', -1]]]}\n",
      "line...\n",
      "{'id': 163803, 'verifiable': 'VERIFIABLE', 'label': 'SUPPORTS', 'claim': 'Ukrainian Soviet Socialist Republic was a founding participant of the UN.', 'evidence': [[[296950, 288668, 'Ukrainian_Soviet_Socialist_Republic', 7]], [[298602, 290067, 'Ukrainian_Soviet_Socialist_Republic', 7], [298602, 290067, 'United_Nations', 0]], [[300696, 291816, 'Ukrainian_Soviet_Socialist_Republic', 7]], [[344347, 327887, 'Ukrainian_Soviet_Socialist_Republic', 7]], [[344994, 328433, 'Ukrainian_Soviet_Socialist_Republic', 7]], [[344997, 328435, 'Ukrainian_Soviet_Socialist_Republic', 7]]]}\n",
      "....\n",
      "docs....\n",
      "['Emblem_of_the_Ukrainian_Soviet_Socialist_Republic', 'Flag_of_the_Moldavian_Autonomous_Soviet_Socialist_Republic', 'Ukrainian_Republic', 'List_of_Presidents_of_Ukraine', 'United_Nations_General_Assembly_Resolution_377']\n",
      "LENGTH = 6\n",
      "for idx and evidence ....... 0\n",
      "0 [[296950, 288668, 'Ukrainian_Soviet_Socialist_Republic', 7]]\n",
      ">>>>>\n",
      "0 [[296950, 288668, 'Emblem_of_the_Ukrainian_Soviet_Socialist_Republic', -1]]\n",
      "for idx and evidence ....... 1\n",
      "1 [[298602, 290067, 'Ukrainian_Soviet_Socialist_Republic', 7], [298602, 290067, 'United_Nations', 0]]\n",
      ">>>>>\n",
      "1 [[298602, 290067, 'Flag_of_the_Moldavian_Autonomous_Soviet_Socialist_Republic', -1], [298602, 290067, 'Flag_of_the_Moldavian_Autonomous_Soviet_Socialist_Republic', -1]]\n",
      "for idx and evidence ....... 2\n",
      "2 [[300696, 291816, 'Ukrainian_Soviet_Socialist_Republic', 7]]\n",
      ">>>>>\n",
      "2 [[300696, 291816, 'Ukrainian_Republic', -1]]\n",
      "for idx and evidence ....... 3\n",
      "3 [[344347, 327887, 'Ukrainian_Soviet_Socialist_Republic', 7]]\n",
      ">>>>>\n",
      "3 [[344347, 327887, 'List_of_Presidents_of_Ukraine', -1]]\n",
      "for idx and evidence ....... 4\n",
      "4 [[344994, 328433, 'Ukrainian_Soviet_Socialist_Republic', 7]]\n",
      ">>>>>\n",
      "4 [[344994, 328433, 'United_Nations_General_Assembly_Resolution_377', -1]]\n",
      "for idx and evidence ....... 5\n",
      "5 [[344997, 328435, 'Ukrainian_Soviet_Socialist_Republic', 7]]\n",
      ">>>>>\n",
      "5 [[344997, 328435, 'United_Nations_General_Assembly_Resolution_377', -1]]\n",
      "IDX =  5 5\n",
      "************* FINAL LINE *********\n",
      "{'id': 163803, 'verifiable': 'VERIFIABLE', 'label': 'SUPPORTS', 'claim': 'Ukrainian Soviet Socialist Republic was a founding participant of the UN.', 'evidence': [[[296950, 288668, 'Emblem_of_the_Ukrainian_Soviet_Socialist_Republic', -1]], [[298602, 290067, 'Flag_of_the_Moldavian_Autonomous_Soviet_Socialist_Republic', -1], [298602, 290067, 'Flag_of_the_Moldavian_Autonomous_Soviet_Socialist_Republic', -1]], [[300696, 291816, 'Ukrainian_Republic', -1]], [[344347, 327887, 'List_of_Presidents_of_Ukraine', -1]], [[344994, 328433, 'United_Nations_General_Assembly_Resolution_377', -1]], [[344997, 328435, 'United_Nations_General_Assembly_Resolution_377', -1]]]}\n",
      "line...\n",
      "{'id': 70041, 'verifiable': 'VERIFIABLE', 'label': 'SUPPORTS', 'claim': '2 Hearts is a musical composition by Minogue.', 'evidence': [[[225394, 230056, '2_Hearts_-LRB-Kylie_Minogue_song-RRB-', 0]], [[317953, 306972, '2_Hearts_-LRB-Kylie_Minogue_song-RRB-', 0]], [[319638, 308345, '2_Hearts_-LRB-Kylie_Minogue_song-RRB-', 0]], [[319643, 308348, '2_Hearts_-LRB-Kylie_Minogue_song-RRB-', 0]]]}\n",
      "....\n",
      "docs....\n",
      "['2_Hearts_-LRB-Kylie_Minogue_song-RRB-', 'Kylie_Minogue_singles_discography', 'Kylie_Minogue', 'X_-LRB-Kylie_Minogue_album-RRB-', 'Giving_You_Up']\n",
      "LENGTH = 4\n",
      "for idx and evidence ....... 0\n",
      "0 [[225394, 230056, '2_Hearts_-LRB-Kylie_Minogue_song-RRB-', 0]]\n",
      ">>>>>\n",
      "0 [[225394, 230056, '2_Hearts_-LRB-Kylie_Minogue_song-RRB-', -1]]\n",
      "for idx and evidence ....... 1\n",
      "1 [[317953, 306972, '2_Hearts_-LRB-Kylie_Minogue_song-RRB-', 0]]\n",
      ">>>>>\n",
      "1 [[317953, 306972, 'Kylie_Minogue_singles_discography', -1]]\n",
      "for idx and evidence ....... 2\n",
      "2 [[319638, 308345, '2_Hearts_-LRB-Kylie_Minogue_song-RRB-', 0]]\n",
      ">>>>>\n",
      "2 [[319638, 308345, 'Kylie_Minogue', -1]]\n",
      "for idx and evidence ....... 3\n",
      "3 [[319643, 308348, '2_Hearts_-LRB-Kylie_Minogue_song-RRB-', 0]]\n",
      ">>>>>\n",
      "3 [[319643, 308348, 'X_-LRB-Kylie_Minogue_album-RRB-', -1]]\n",
      "IDX =  3 5\n",
      "************* FINAL LINE *********\n",
      "{'id': 70041, 'verifiable': 'VERIFIABLE', 'label': 'SUPPORTS', 'claim': '2 Hearts is a musical composition by Minogue.', 'evidence': [[[225394, 230056, '2_Hearts_-LRB-Kylie_Minogue_song-RRB-', -1]], [[317953, 306972, 'Kylie_Minogue_singles_discography', -1]], [[319638, 308345, 'Kylie_Minogue', -1]], [[319643, 308348, 'X_-LRB-Kylie_Minogue_album-RRB-', -1], [-1, None, '2_Hearts_-LRB-Kylie_Minogue_song-RRB-', -1]]]}\n",
      "line...\n",
      "{'id': 202314, 'verifiable': 'VERIFIABLE', 'label': 'REFUTES', 'claim': 'The New Jersey Turnpike has zero shoulders.', 'evidence': [[[238335, 240393, 'New_Jersey_Turnpike', 15]]]}\n",
      "....\n",
      "docs....\n",
      "['Interstate_95_in_New_Jersey', 'List_of_turnpikes_in_New_Jersey', 'New_Jersey_Turnpike', 'Newark_Bay_Bridge', 'New_Jersey_Route_495']\n",
      "LENGTH = 1\n",
      "for idx and evidence ....... 0\n",
      "0 [[238335, 240393, 'New_Jersey_Turnpike', 15]]\n",
      ">>>>>\n",
      "0 [[238335, 240393, 'Interstate_95_in_New_Jersey', -1]]\n",
      "IDX =  0 5\n",
      "************* FINAL LINE *********\n",
      "{'id': 202314, 'verifiable': 'VERIFIABLE', 'label': 'REFUTES', 'claim': 'The New Jersey Turnpike has zero shoulders.', 'evidence': [[[238335, 240393, 'Interstate_95_in_New_Jersey', -1], [-1, None, 'Interstate_95_in_New_Jersey', -1], [-1, None, 'List_of_turnpikes_in_New_Jersey', -1], [-1, None, 'New_Jersey_Turnpike', -1], [-1, None, 'Newark_Bay_Bridge', -1]]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fever_root = 'data/'\n",
    "working_dir = 'working/data/'\n",
    "cnt = 0\n",
    "print(\"Saving prepared dataset to {}\".format(\"training/{0}.ns.pages.p{1}.jsonl\".format(split,k)))\n",
    "with open(fever_root + \"data/fever-data/{0}.jsonl\".format(split),\"r\") as f_in:\n",
    "    with open(working_dir + \"training/{0}_pipeline.ns.pages.p{1}.jsonl\".format(split,k),\"w+\") as f_out:\n",
    "        for line in tqdm(f_in.readlines()):\n",
    "            line = json.loads(line)\n",
    "            print(\"line...\")\n",
    "            print(line)\n",
    "            print(\"....\")\n",
    "            doc_names, doc_scores = ranker.closest_docs(line['claim'], k)\n",
    "            pp = list(doc_names)\n",
    "            print(\"docs....\")\n",
    "            print(pp)\n",
    "            print(\"LENGTH =\", len(line['evidence']))\n",
    "            for idx,evidence_group in enumerate(line['evidence']):\n",
    "                print(\"for idx and evidence ....... {}\".format(idx))\n",
    "                print(idx,evidence_group)\n",
    "                for evidence in evidence_group:\n",
    "                    if idx<len(pp):\n",
    "                        evidence[2] = pp[idx]\n",
    "                        evidence[3] = -1\n",
    "                    else:\n",
    "                        evidence[2] = pp[-1]\n",
    "                        evidence[3] = -1\n",
    "                print(\">>>>>\")\n",
    "                print(idx,evidence_group)\n",
    "#             if (idx < len(line['evidence'])):\n",
    "#                 ev = [-1, -1, pp[idx]]\n",
    "            print(\"IDX = \", idx, len(pp))\n",
    "            if len(pp) > idx:\n",
    "                for i in range(len(pp)-1-idx):\n",
    "                    ev = [[-1, None, pp[i], -1]]\n",
    "                    evidence_group.extend(ev)\n",
    "            print(\"************* FINAL LINE *********\")\n",
    "            print(line)\n",
    "            cnt += 1\n",
    "            if cnt > 3:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-school",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
