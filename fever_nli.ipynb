{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEVER \n",
    "\n",
    "A large part of the work here is to process the datasets and prepare them for training.\n",
    "\n",
    "In this notebook, we will first focus on extracting the data from the pre-processed Wiki corpus provided by [fever.ai](https://fever.ai/dataset/fever.html).\n",
    "\n",
    "The datasets are available as JSONL files. \n",
    "\n",
    "The data is available in a [docker image](https://hub.docker.com/r/feverai/common), 21GB in size. The container is created and the volume /local/ from it is mounted and made available to our [container](https://github.com/dmayukh/fakenews/Dockerfile) \n",
    "\n",
    "We use the following repos for reference code:\n",
    "\n",
    "- [fever-baselines](https://github.com/klimzaporojets/fever-baselines.git)\n",
    "- [fever-allennlp-reader](https://github.com/j6mes/fever-allennlp-reader)\n",
    "- [fever-allennlp](https://github.com/j6mes/fever-allennlp)\n",
    "\n",
    "Note, AllenNLP here is used only for the NLI training, using models such as Decomposable Attention, Elmo + ESIM, ESIM etc. We will not use those for our work here.\n",
    "\n",
    "\n",
    "We will install a few dependencies such as:\n",
    "- numpy>=1.15\n",
    "- regex\n",
    "- allennlp==2.5.0\n",
    "- fever-scorer==2.0.39\n",
    "- fever-drqa==1.0.13\n",
    "\n",
    "The following packages are installed by the above dependencies\n",
    "- torchvision-0.9.1\n",
    "- google_cloud_storage-1.38.0\n",
    "- overrides==3.1.0\n",
    "- transformers-4.6.1\n",
    "- spacy-3.0.6\n",
    "- sentencepiece-0.1.96\n",
    "- torch-1.8.1\n",
    "- wandb-0.10.33\n",
    "- lmdb-1.2.1\n",
    "- jsonnet-0.17.0\n",
    "\n",
    "We do not really need allennlp or fever-scorer as of yet, we would only need DrQA. We would prefer to use the DrQA from the official github, but for now we will go with what was prepackaged by the [j6mes](https://pypi.org/project/fever-drqa/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the ESIM model on Fever dataset\n",
    "\n",
    "The supplied dataset in the train.jsonl has NEI (not enough info) classes which do not have evidences annotated.\n",
    "\n",
    "First we would prepare the dataset by generating closest document matches for the NEI classes.\n",
    "\n",
    "The resulting dataset would have the original samples and for the NEI classes the evidence would contain the predicted, i.e. documents that match closely with the claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mda.src.dataset.DatasetGenerator import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_generator = DatasetGenerator(dataset_root='data/data/',out_dir='working/data/training/', database_path='data/data/fever/fever.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data to working/data/training//train.ns.pages.p5.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145449/145449 [25:12<00:00, 96.19it/s] \n"
     ]
    }
   ],
   "source": [
    "ds_generator.generate_nei_evidences('train', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mda.src.dataset.DatasetReader import DatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145449/145449 [00:01<00:00, 90574.03it/s] \n",
      "100%|██████████| 145449/145449 [00:01<00:00, 142085.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(2,), dtype=tf.string, name=None), TensorSpec(shape=(3,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "infile = 'working/data/training/train.ns.pages.p5.jsonl'\n",
    "dsreader = DatasetReader(in_file=infile,label_checkpoint_file=None, database_path='data/data/fever/fever.db')\n",
    "raw, data = dsreader.read()\n",
    "ds_train = dsreader.get_dataset()\n",
    "print(ds_train.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b'[START] nikolaj coster waldau worked with the fox broadcasting company . [END]',\n",
      "       b'He then played Detective John Amsterdam in the short-lived Fox television series New Amsterdam -LRB- 2008 -RRB- , as well as appearing as Frank Pike in the 2009 Fox television film Virtuality , originally intended as a pilot . The Fox Broadcasting Company -LRB- often shortened to Fox and stylized as FOX -RRB- is an American English language commercial broadcast television network that is owned by the Fox Entertainment Group subsidiary of 21st Century Fox .'],\n",
      "      dtype=object)>, <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 0, 1], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for d in ds_train.take(1):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dev data\n",
    "\n",
    "NOTE: the dev data is sampled differently than training data when running evaluation, this is because during validation, we are supposed to select the relevant pages and the sentences from those pages which will be used for our evaluation task, but during the training validation data comes from the dev dataset for which the pages and sentences chosen would be the ones annotated in the dataset and therefore which should be processed just like the train data, i.e. using the annotated evidences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate NEI evidences for dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9999 [00:00<08:48, 18.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data to working/data/training//paper_dev.ns.pages.p5.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [02:19<00:00, 71.57it/s] \n"
     ]
    }
   ],
   "source": [
    "ds_generator.generate_nei_evidences('paper_dev', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:00<00:00, 179961.83it/s]\n",
      "100%|██████████| 9999/9999 [00:00<00:00, 24187.47it/s]\n"
     ]
    }
   ],
   "source": [
    "infile = 'working/data/training/paper_dev.ns.pages.p5.jsonl'\n",
    "label_checkpoint_file = 'working/data/training/label_encoder_train.pkl'\n",
    "#note, use type = 'train' since formatting would be like the train examples\n",
    "dsreader = DatasetReader(in_file=infile,label_checkpoint_file=label_checkpoint_file, database_path='data/data/fever/fever.db', type='train')\n",
    "raw_dev, data_dev = dsreader.read()\n",
    "ds_dev = dsreader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b'[START] colin kaepernick became a starting quarterback during the ers rd season in the national football league . [END]',\n",
      "       b'During the 2013 season , his first full season as a starter , Kaepernick helped the 49ers reach the NFC Championship , losing to the Seattle Seahawks .'],\n",
      "      dtype=object)>, <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 0, 0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for d in ds_dev.take(1):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_text as text\n",
    "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_tokenizer_params=dict(lower_case=True)\n",
    "reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
    "bert_vocab_args = dict(\n",
    "    # The target vocabulary size\n",
    "    vocab_size = 8000,\n",
    "    # Reserved tokens that must be included in the vocabulary\n",
    "    reserved_tokens=reserved_tokens,\n",
    "    # Arguments for `text.BertTokenizer`\n",
    "    bert_tokenizer_params=bert_tokenizer_params,\n",
    "    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n",
    "    learn_params={},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the vocab is an expensive operation and needs to be done using the full corpus of data, i.e. not just the sentences, but using the entire body text from the training dataset. If the vocab is already generated, use the vocab file to initialize the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer_params=dict(lower_case=True)\n",
    "vocab_file_out = 'working/data/fever_vocab.txt'\n",
    "pt_tokenizer = text.BertTokenizer(vocab_file_out, **bert_tokenizer_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the vocab file is not available, generate the vocab file. Use the full dataset text generator for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:00<00:00, 56881.19it/s]\n",
      "100%|██████████| 9999/9999 [00:00<00:00, 192957.13it/s]\n"
     ]
    }
   ],
   "source": [
    "infile = 'working/data/training/paper_dev.ns.pages.p5.jsonl'\n",
    "#note, use type = 'train' since formatting would be like the train examples\n",
    "dsreader = DatasetReader(in_file=infile,label_checkpoint_file=None, database_path='data/data/fever/fever.db', type='train', fullbodytext=True)\n",
    "raw_train_all, data_train_all = dsreader.read()\n",
    "ds_train_tup = dsreader.get_dataset()\n",
    "ds_train_text = ds_train_tup.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 11s, sys: 1.22 s, total: 2min 13s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pt_vocab = bert_vocab.bert_vocab_from_dataset(\n",
    "    ds_train_text.batch(1000).prefetch(2),\n",
    "    **bert_vocab_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vocab_file(filepath, vocab):\n",
    "    print(\"Saving vocab file to {}\".format(filepath))\n",
    "    with open(filepath, 'w') as f:\n",
    "        for token in vocab:\n",
    "            print(token, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving vocab file to working/data/fever_vocab.txt\n"
     ]
    }
   ],
   "source": [
    "vocab_file_out = 'working/data/fever_vocab.txt'\n",
    "write_vocab_file(vocab_file_out, pt_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the data and prepare the tensors for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (60,), types: tf.int64>\n",
      "<MapDataset shapes: (60,), types: tf.int64>\n",
      "<BatchDataset shapes: (((64, 60), (64, 60)), (64, 3)), types: ((tf.int64, tf.int64), tf.int32)>\n",
      "((TensorSpec(shape=(64, 60), dtype=tf.int64, name=None), TensorSpec(shape=(64, 60), dtype=tf.int64, name=None)), TensorSpec(shape=(64, 3), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "MAX_SEQ_LEN = 60\n",
    "BUFFER_SIZE = 32000\n",
    "def tokenize_and_pad(text, max_len):\n",
    "    segment = pt_tokenizer.tokenize(text).merge_dims(1, -1)\n",
    "    inp = segment.to_tensor(shape=[None, max_len])\n",
    "    return inp[0]\n",
    "\n",
    "h = ds_train.map(lambda x, y: tokenize_and_pad(x[0], MAX_SEQ_LEN))\n",
    "e = ds_train.map(lambda x, y: tokenize_and_pad(x[1], MAX_SEQ_LEN))\n",
    "l = ds_train.map(lambda x, y: y)\n",
    "print(h)\n",
    "print(e)\n",
    "f = tf.data.Dataset.zip((h,e))\n",
    "d = tf.data.Dataset.zip((f,l))\n",
    "dataset_train = d.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset_train)\n",
    "print(dataset_train.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (60,), types: tf.int64>\n",
      "<MapDataset shapes: (60,), types: tf.int64>\n",
      "<BatchDataset shapes: (((64, 60), (64, 60)), (64, 3)), types: ((tf.int64, tf.int64), tf.int32)>\n",
      "((TensorSpec(shape=(64, 60), dtype=tf.int64, name=None), TensorSpec(shape=(64, 60), dtype=tf.int64, name=None)), TensorSpec(shape=(64, 3), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "MAX_SEQ_LEN = 60\n",
    "BUFFER_SIZE = 32000\n",
    "def tokenize_and_pad(text, max_len):\n",
    "    segment = pt_tokenizer.tokenize(text).merge_dims(1, -1)\n",
    "    inp = segment.to_tensor(shape=[None, max_len])\n",
    "    return inp[0]\n",
    "\n",
    "h = ds_dev.map(lambda x, y: tokenize_and_pad(x[0], MAX_SEQ_LEN))\n",
    "e = ds_dev.map(lambda x, y: tokenize_and_pad(x[1], MAX_SEQ_LEN))\n",
    "l = ds_dev.map(lambda x, y: y)\n",
    "print(h)\n",
    "print(e)\n",
    "f = tf.data.Dataset.zip((h,e))\n",
    "d = tf.data.Dataset.zip((f,l))\n",
    "dataset_test = d.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset_test)\n",
    "print(dataset_test.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the glove embeddings\n",
    "\n",
    "If this is the first time parsing glove, we will load them from the file downloaded from <> and prepare the embedding matrix.\n",
    "\n",
    "If we already have an embedding matrix saved, we will simply load them from the saved object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0']\n",
      "Loaded an embedding matrix of shape (8001, 300)\n"
     ]
    }
   ],
   "source": [
    "npzfile = np.load(\"working/data/embedding_mappings_300d.npz\")\n",
    "print(npzfile.files)\n",
    "embedding_matrix = npzfile['arr_0']\n",
    "print(\"Loaded an embedding matrix of shape\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we did not have saved embeddings, we will need to parse them from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.6B.50d.txt\n",
      "glove.6B.100d.txt\n",
      "glove.6B.200d.txt\n",
      "glove.6B.300d.txt\n",
      "Reading lines from file glove.6B.300d.txt\n"
     ]
    }
   ],
   "source": [
    "import zipfile, io\n",
    "glove_zip_file = \"entailment/data/glove.6B.zip\"\n",
    "glove_vectors_file = \"glove.6B.300d.txt\"\n",
    "embeddings_index = {}\n",
    "with zipfile.ZipFile(glove_zip_file) as z:\n",
    "        for info in z.infolist():\n",
    "            print(info.filename)\n",
    "            if glove_vectors_file in info.filename:\n",
    "                # read the file\n",
    "                print(\"Reading lines from file {}\".format(glove_vectors_file))\n",
    "                with io.TextIOWrapper(z.open(glove_vectors_file), encoding=\"utf-8\") as f:\n",
    "                    for line in f:\n",
    "                        terms = line.split()\n",
    "                        word = terms[0]\n",
    "                        coefs = np.asarray(terms[1:], dtype='float32')\n",
    "                        \n",
    "                        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the embedding matrix from the embedding index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = embeddings_index['start'].shape[0]\n",
    "vocab_size = 8000\n",
    "embedding_matrix = np.zeros((vocab_size + 1, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d is already a batch of 32 examples\n",
    "for d in ds.batch(1):\n",
    "    emb = pt_tokenizer.tokenize(d[0])\n",
    "    embd = pt_tokenizer.detokenize(emb)\n",
    "    word_batch = [[w[0].decode() for w in w_np] for w_np in [word.numpy() for word in embd]]\n",
    "    index_batch = [[w[0] for w in w_np] for w_np in [word.numpy() for word in emb]]\n",
    "    for w_batch, i_batch in zip(word_batch, index_batch):\n",
    "        for w, i in zip(w_batch, i_batch):\n",
    "            embedding_vector = embeddings_index.get(w)\n",
    "            if embedding_vector is not None:\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the embedding matrix to a compressed numpy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = \"working/data/embedding_mappings_300d.npz\"\n",
    "np.savez(embedding_file, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base line NLI model using BiLSTM\n",
    "\n",
    "From A large annotated corpus for learning natural language inference [Bowman et al.](https://arxiv.org/pdf/1508.05326v1.pdf), we use the idea of a network based on a BiLSTM. Instead of using 100D embeddings, we use 300D embeddings and use just one 'relu' layer instead of 2 stacked 'tanh' layers used by the authors of the paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "hypothesis (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "evidence (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 300)    2400300     hypothesis[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 300)    2400300     evidence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 600)          1442400     embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 600)          1442400     embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1200)         0           bidirectional[0][0]              \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           19216       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            51          dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,704,667\n",
      "Trainable params: 2,904,067\n",
      "Non-trainable params: 4,800,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size= 8000\n",
    "dim = 300\n",
    "inp1 = keras.Input(shape=(None, ), name = \"hypothesis\")\n",
    "inp2 = keras.Input(shape=(None, ), name = \"evidence\")\n",
    "embedding_hyp_layer = tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size+1,\n",
    "        output_dim=dim,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable=False)\n",
    "embedding_evi_layer = tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size+1,\n",
    "        output_dim=dim,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable=False)\n",
    "x_hyp = embedding_hyp_layer(inp1)\n",
    "x_evi = embedding_evi_layer(inp2)\n",
    "lstm_layer1 = tf.keras.layers.Bidirectional(tf.keras.layers.RNN(tf.keras.layers.LSTMCell(dim)))(x_hyp)\n",
    "lstm_layer2 = tf.keras.layers.Bidirectional(tf.keras.layers.RNN(tf.keras.layers.LSTMCell(dim)))(x_evi)\n",
    "w = keras.layers.concatenate([lstm_layer1, lstm_layer2], axis = 1)\n",
    "x1 = tf.keras.layers.Dense(16, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu')(w)\n",
    "x2 = tf.keras.layers.Dropout(0.3)(x1)\n",
    "output = tf.keras.layers.Dense(3, activation='softmax')(x2)\n",
    "model = keras.Model(inputs=[inp1, inp2], outputs=output)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=tf.keras.optimizers.Adam(), \n",
    "          metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf tmp/checkpoint_fever_nli*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'tmp/checkpoint_fever_nli'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "2272/2272 [==============================] - 623s 248ms/step - loss: 0.7429 - accuracy: 0.7070 - val_loss: 0.8254 - val_accuracy: 0.6328\n",
      "Epoch 2/12\n",
      "2272/2272 [==============================] - 605s 245ms/step - loss: 0.6082 - accuracy: 0.7680 - val_loss: 0.8183 - val_accuracy: 0.6541\n",
      "Epoch 3/12\n",
      "2272/2272 [==============================] - 606s 245ms/step - loss: 0.5331 - accuracy: 0.8034 - val_loss: 0.8382 - val_accuracy: 0.6535\n",
      "Epoch 4/12\n",
      "2272/2272 [==============================] - 604s 244ms/step - loss: 0.4813 - accuracy: 0.8252 - val_loss: 0.9818 - val_accuracy: 0.6402\n",
      "Epoch 5/12\n",
      "2272/2272 [==============================] - 606s 245ms/step - loss: 0.4381 - accuracy: 0.8421 - val_loss: 1.0801 - val_accuracy: 0.6344\n",
      "Epoch 6/12\n",
      "2272/2272 [==============================] - 604s 245ms/step - loss: 0.4000 - accuracy: 0.8574 - val_loss: 1.1629 - val_accuracy: 0.6336\n",
      "Epoch 7/12\n",
      "2272/2272 [==============================] - 604s 244ms/step - loss: 0.3680 - accuracy: 0.8683 - val_loss: 1.2821 - val_accuracy: 0.6327\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset_train, epochs = 12, validation_data=dataset_test, callbacks=[stop_early, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 23s 44ms/step - loss: 0.8134 - accuracy: 0.6581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.813413679599762, 0.6580528616905212]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_filepath = 'tmp/checkpoint_fever_nli'\n",
    "model.load_weights(checkpoint_filepath)\n",
    "model.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Metrics for training FEVER dataset, 145K samples (glove 300d)')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1,1)\n",
    "x = np.arange(len(history.history['loss']))\n",
    "ax.plot(x, history.history['loss'], label=\"train loss\")\n",
    "ax.plot(x, history.history['val_loss'], label=\"val loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"categorial cross entropy loss\")\n",
    "ax.legend()\n",
    "plt.title(\"Metrics for training FEVER dataset, 145K samples (glove 300d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network\n",
    "\n",
    "As observed above, the BiLSTM network with a relu dense layer did'nt do well even though it seemed to have done well in the SNLI tasks. One reason could be the length of the hypothesis in FEVER dataset. In SNLI dataset, the premise and the hypothesis are pretty much of the same length, whereas in our case the hypothesis is much longer due to the concatenation of multiple sentences from multiple documents.\n",
    "\n",
    "We look at the results of the FEVER 2018 workshop where the 3rd place holder <b>UCL Machine Reading Group></b> with their [Four Factor Framework For Fact Finding (HexaF)](https://aclanthology.org/W18-5515.pdf) paper used a similar network with local inferenece encoding. They use an ESIM model [Chen et. al.](https://arxiv.org/abs/1609.06038) with the novelty in they way the results are aggregated.\n",
    "\n",
    "We will use a similar approach, but we will use Bert tokenizers and use a simple aggregation technique instead of the complex MLP and majority vote based technique used by the authors.\n",
    "\n",
    "The authors also used a pre-trained ESIM model on the SNLI dataset and fine tuned it on the FEVER dataset, which we did not do due to lack of time. One way to improve our results would be to perform this step.\n",
    "\n",
    "We do much better than the original FEVER paper which had a classification accuracy of <b>32.57%</b>, and ignoring the requirement for correct evidence (NoScoreEv) the accuracy was <b>52.09%</b>, our results were <b>35.96%</b> and <b>56.39%</b> respectively.\n",
    "\n",
    "We however do not perform better than <b>UCL Machine Reading Group</b> whose best score was <b>65.41%</b>. It however is not clear from their paper if this was a (NoScoreEv) or the actual FEVER score.\n",
    "\n",
    "[The Fact Extraction and VERification (FEVER) Shared Task](https://aclanthology.org/W18-5501v3.pdf) details the scores for the teams, arranges by the label accuracy and the fever score on the test dataset.\n",
    "\n",
    "Our label accuracy was <b>57.32%</b> and the fever score was <b>34.92%</b> which should have put us at 16th position by fever score.\n",
    "Our label accuracy is however quite good and would have put us in the <b>top 6</b> if we were to only look at the accuracy of predicting the right label and ignore if we has selected the right evidence (sentence) to support or refute the claim. \n",
    "\n",
    "We refer to 'Keras ESIM', an implementation of [Chen et. al.](https://arxiv.org/abs/1609.06038) <b>Enhanced LSTM for Natural Language Inference</b> for the task of natural language inference.\n",
    "\n",
    "Reference: https://github.com/dzdrav/kerasESIM\n",
    "\n",
    "Optionally we could have used this https://gist.github.com/namakemono/f4f273dbc63fc2174940415a9f689a6f. The network representation is simpler in this form of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, None, 600), dtype=tf.float32, name=None), name='finaldecoder/concat:0', description=\"created by layer 'finaldecoder'\")\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "hypothesis (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "evidence (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 300)    2400300     hypothesis[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 300)    2400300     evidence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 300)    0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 300)    0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 600)    1442400     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 600)    1442400     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, None, None)   0           bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, None, None)   0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, None)   0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None, None)   0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, None, 600)    0           lambda_1[0][0]                   \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, None, 600)    0           lambda[0][0]                     \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, None, 600)    0           bidirectional_2[0][0]            \n",
      "                                                                 dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, None, 600)    0           bidirectional_2[0][0]            \n",
      "                                                                 dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, None, 600)    0           bidirectional_3[0][0]            \n",
      "                                                                 dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, None, 600)    0           bidirectional_3[0][0]            \n",
      "                                                                 dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 2400)   0           bidirectional_2[0][0]            \n",
      "                                                                 dot_1[0][0]                      \n",
      "                                                                 subtract[0][0]                   \n",
      "                                                                 multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, 2400)   0           bidirectional_3[0][0]            \n",
      "                                                                 dot_2[0][0]                      \n",
      "                                                                 subtract_1[0][0]                 \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Compresser (TimeDistributed)    (None, None, 300)    720300      concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 300)    0           Compresser[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 300)    0           Compresser[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "finaldecoder (Bidirectional)    (None, None, 600)    1442400     dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 600)          0           finaldecoder[0][0]               \n",
      "                                                                 finaldecoder[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 600)          0           finaldecoder[0][0]               \n",
      "                                                                 finaldecoder[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2400)         0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "                                                                 global_average_pooling1d[1][0]   \n",
      "                                                                 global_max_pooling1d[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2400)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense300_ (Dense)               (None, 100)          240100      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 100)          0           dense300_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "judge300_ (Dense)               (None, 3)            303         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,088,503\n",
      "Trainable params: 5,287,903\n",
      "Non-trainable params: 4,800,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Simple model\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import *\n",
    "\n",
    "vocab_size= 8000\n",
    "dim = 300\n",
    "inp1 = keras.Input(shape=(None, ), name = \"hypothesis\")\n",
    "inp2 = keras.Input(shape=(None, ), name = \"evidence\")\n",
    "\n",
    "embedding_hyp_layer = Embedding(\n",
    "        input_dim=vocab_size+1,\n",
    "        output_dim=dim,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable=False)\n",
    "embedding_evi_layer = Embedding(\n",
    "        input_dim=vocab_size+1,\n",
    "        output_dim=dim,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable=False)\n",
    "\n",
    "\n",
    "x_hyp = embedding_hyp_layer(inp1)\n",
    "x_hyp = tf.keras.layers.Dropout(0.5)(x_hyp)\n",
    "\n",
    "x_evi = embedding_evi_layer(inp2)\n",
    "x_evi = tf.keras.layers.Dropout(0.5)(x_evi)\n",
    "\n",
    "#Encoder = Bidirectional(CuDNNLSTM(units=300, return_sequences=True, kernel_initializer='RandomNormal'))\n",
    "\n",
    "lstm_layer1 = tf.keras.layers.Bidirectional(tf.keras.layers.RNN(tf.keras.layers.LSTMCell(dim), return_sequences=True))(x_hyp)\n",
    "\n",
    "lstm_layer2 = tf.keras.layers.Bidirectional(tf.keras.layers.RNN(tf.keras.layers.LSTMCell(dim), return_sequences=True))(x_evi)\n",
    "\n",
    "# lstm_layer1 = Encoder(x_hyp)\n",
    "# lstm_layer2 = Encoder(x_evi)\n",
    "\n",
    "F_p, F_h = lstm_layer1, lstm_layer2\n",
    "Eph = keras.layers.Dot(axes=(2, 2))([F_h, F_p])  # [batch_size, Hsize, Psize]\n",
    "Eh = Lambda(lambda x: keras.activations.softmax(x))(Eph)  # [batch_size, Hsize, Psize]\n",
    "Ep = keras.layers.Permute((2, 1))(Eph)  # [batch_size, Psize, Hsize)\n",
    "Ep = Lambda(lambda x: keras.activations.softmax(x))(Ep)  # [batch_size, Psize, Hsize]\n",
    "    \n",
    "    \n",
    "    \n",
    "# 4, Normalize score matrix, encoder premesis and get alignment\n",
    "PremAlign = keras.layers.Dot((2, 1))([Ep, lstm_layer2]) # [-1, Psize, dim]\n",
    "HypoAlign = keras.layers.Dot((2, 1))([Eh, lstm_layer1]) # [-1, Hsize, dim]\n",
    "mm_1 = keras.layers.Multiply()([lstm_layer1, PremAlign])\n",
    "mm_2 = keras.layers.Multiply()([lstm_layer2, HypoAlign])\n",
    "sb_1 = keras.layers.Subtract()([lstm_layer1, PremAlign])\n",
    "sb_2 = keras.layers.Subtract()([lstm_layer2, HypoAlign])\n",
    "    \n",
    "\n",
    "# concat [a_, a~, a_ * a~, a_ - a~], isto za b_, b~\n",
    "PremAlign = keras.layers.Concatenate()([lstm_layer1, PremAlign, sb_1, mm_1,])  # [batch_size, Psize, 2*unit]\n",
    "HypoAlign = keras.layers.Concatenate()([lstm_layer2, HypoAlign, sb_2, mm_2])  # [batch_size, Hsize, 2*unit]\n",
    "\n",
    "# ff layer w/RELU activation\n",
    "Compresser = tf.keras.layers.TimeDistributed(Dense(300,\n",
    "                                   kernel_regularizer=l2(0.0),\n",
    "                                   bias_regularizer=l2(0.0),\n",
    "                                   activation='relu'),\n",
    "                             name='Compresser')\n",
    "\n",
    "PremAlign = Compresser(PremAlign)\n",
    "HypoAlign = Compresser(HypoAlign)\n",
    "    \n",
    "# 5, Final biLST < Encoder + Softmax Classifier\n",
    "# Decoder = Bidirectional(CuDNNLSTM(units=100, return_sequences=True, kernel_initializer='RandomNormal'),\n",
    "#                         name='finaldecoder')  # [-1,2*units]\n",
    "\n",
    "Decoder = tf.keras.layers.Bidirectional(tf.keras.layers.RNN(tf.keras.layers.LSTMCell(dim), return_sequences=True), name='finaldecoder')\n",
    "\n",
    "\n",
    "PremAlign = Dropout(0.5)(PremAlign)\n",
    "HypoAlign = Dropout(0.5)(HypoAlign)\n",
    "final_p = Decoder(PremAlign)\n",
    "final_h = Decoder(HypoAlign)\n",
    "print(final_p)\n",
    "\n",
    "AveragePooling = tf.keras.layers.GlobalAveragePooling1D()\n",
    "MaxPooling = tf.keras.layers.GlobalMaxPooling1D()\n",
    "\n",
    "# AveragePooling = Lambda(lambda x: K.mean(x, axis=1)) # outs [-1, dim]\n",
    "# MaxPooling = Lambda(lambda x: K.max(x, axis=1)) # outs [-1, dim]\n",
    "avg_p = AveragePooling(final_p)\n",
    "avg_h = AveragePooling(final_h)\n",
    "max_p = MaxPooling(final_p)\n",
    "max_h = MaxPooling(final_h)\n",
    "# concat of avg and max pooling for hypothesis and premise\n",
    "Final = keras.layers.Concatenate()([avg_p, max_p, avg_h, max_h])\n",
    "# dropout layer\n",
    "Final = Dropout(0.5)(Final)\n",
    "# ff layer w/tanh activation\n",
    "Final = Dense(100,\n",
    "              kernel_regularizer=l2(0.0),\n",
    "              bias_regularizer=l2(0.0),\n",
    "              name='dense300_',\n",
    "              activation='tanh')(Final)\n",
    "\n",
    "# last dropout factor\n",
    "factor = 1\n",
    "# if self.LastDropoutHalf:\n",
    "#     factor = 2\n",
    "Final = Dropout(0.5 / factor)(Final)\n",
    "\n",
    "# softmax classifier\n",
    "Final = Dense(3,\n",
    "              activation='softmax',\n",
    "              name='judge300_')(Final)\n",
    "model = tf.keras.Model(inputs=[inp1, inp2], outputs=Final)\n",
    "\n",
    "LearningRate = 4e-4\n",
    "GradientClipping = 10.0\n",
    "\n",
    "# Optimizer = keras.optimizers.Adam(lr = LearningRate,\n",
    "#             clipnorm = GradientClipping)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf tmp/attention_esim/checkpoint_fever_rte_esim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'tmp/attention_esim/checkpoint_fever_rte_esim'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2272/2272 [==============================] - 909s 378ms/step - loss: 0.6742 - accuracy: 0.7235 - val_loss: 0.6593 - val_accuracy: 0.6953\n",
      "Epoch 2/30\n",
      "2272/2272 [==============================] - 907s 379ms/step - loss: 0.5241 - accuracy: 0.7964 - val_loss: 0.6712 - val_accuracy: 0.7250\n",
      "Epoch 3/30\n",
      "2272/2272 [==============================] - 907s 379ms/step - loss: 0.4570 - accuracy: 0.8257 - val_loss: 0.5636 - val_accuracy: 0.7689\n",
      "Epoch 4/30\n",
      "2272/2272 [==============================] - 905s 378ms/step - loss: 0.4174 - accuracy: 0.8430 - val_loss: 0.6242 - val_accuracy: 0.7549\n",
      "Epoch 5/30\n",
      "2272/2272 [==============================] - 907s 379ms/step - loss: 0.3880 - accuracy: 0.8546 - val_loss: 0.5584 - val_accuracy: 0.7841\n",
      "Epoch 6/30\n",
      "2272/2272 [==============================] - 908s 379ms/step - loss: 0.3704 - accuracy: 0.8621 - val_loss: 0.5369 - val_accuracy: 0.7905\n",
      "Epoch 7/30\n",
      "2272/2272 [==============================] - 905s 378ms/step - loss: 0.3538 - accuracy: 0.8695 - val_loss: 0.5384 - val_accuracy: 0.7910\n",
      "Epoch 8/30\n",
      "2272/2272 [==============================] - 907s 379ms/step - loss: 0.3410 - accuracy: 0.8740 - val_loss: 0.5401 - val_accuracy: 0.7959\n",
      "Epoch 9/30\n",
      "2272/2272 [==============================] - 904s 378ms/step - loss: 0.3344 - accuracy: 0.8763 - val_loss: 0.5442 - val_accuracy: 0.7930\n",
      "Epoch 10/30\n",
      "2272/2272 [==============================] - 907s 379ms/step - loss: 0.3279 - accuracy: 0.8793 - val_loss: 0.5187 - val_accuracy: 0.8039\n",
      "Epoch 11/30\n",
      "2272/2272 [==============================] - 906s 379ms/step - loss: 0.3198 - accuracy: 0.8821 - val_loss: 0.5425 - val_accuracy: 0.7993\n",
      "Epoch 12/30\n",
      "2272/2272 [==============================] - 906s 379ms/step - loss: 0.3128 - accuracy: 0.8849 - val_loss: 0.5403 - val_accuracy: 0.8016\n",
      "Epoch 13/30\n",
      "2272/2272 [==============================] - 907s 379ms/step - loss: 0.3122 - accuracy: 0.8855 - val_loss: 0.5901 - val_accuracy: 0.7945\n",
      "Epoch 14/30\n",
      "2272/2272 [==============================] - 906s 379ms/step - loss: 0.3040 - accuracy: 0.8887 - val_loss: 0.5346 - val_accuracy: 0.8056\n",
      "Epoch 15/30\n",
      "2272/2272 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.8885"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset_train, epochs = 30, validation_data=dataset_test, callbacks=[stop_early, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 31s 89ms/step - loss: 0.5216 - accuracy: 0.8085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5215820074081421, 0.8084936141967773]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_filepath = 'tmp/attention_esim/checkpoint_fever_rte_esim'\n",
    "model.load_weights(checkpoint_filepath)\n",
    "model.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Metrics for training SNLI dataset, 70K samples (glove 100d)')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1,1)\n",
    "x = np.arange(len(history.history['loss']))\n",
    "ax.plot(x, history.history['loss'], label=\"train loss\")\n",
    "ax.plot(x, history.history['val_loss'], label=\"val loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"categorial cross entropy loss\")\n",
    "ax.legend()\n",
    "plt.title(\"Metrics for training FEVER dataset, 145K samples (glove 300d)\")\n",
    "#history.history['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (60,), types: tf.int64>\n",
      "<MapDataset shapes: (60,), types: tf.int64>\n",
      "<BatchDataset shapes: (((64, 60), (64, 60)), (64, 3)), types: ((tf.int64, tf.int64), tf.int32)>\n",
      "((TensorSpec(shape=(64, 60), dtype=tf.int64, name=None), TensorSpec(shape=(64, 60), dtype=tf.int64, name=None)), TensorSpec(shape=(64, 3), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "MAX_SEQ_LEN = 60\n",
    "BUFFER_SIZE = 32000\n",
    "def tokenize_and_pad(text, max_len):\n",
    "    segment = pt_tokenizer.tokenize(text).merge_dims(1, -1)\n",
    "    inp = segment.to_tensor(shape=[None, max_len])\n",
    "    return inp[0]\n",
    "\n",
    "h = ds_dev.map(lambda x, y: tokenize_and_pad(x[0], MAX_SEQ_LEN))\n",
    "e = ds_dev.map(lambda x, y: tokenize_and_pad(x[1], MAX_SEQ_LEN))\n",
    "l = ds_dev.map(lambda x, y: y)\n",
    "print(h)\n",
    "print(e)\n",
    "f = tf.data.Dataset.zip((h,e))\n",
    "d = tf.data.Dataset.zip((f,l))\n",
    "#do not shuffle for precision calculation\n",
    "dataset_test_val = d.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset_test_val)\n",
    "print(dataset_test_val.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (64, 3), types: tf.int32>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, ..., 0, 0, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the labels from the dev dataset and convert them into onehot\n",
    "ds_y = dataset_test_val.map(lambda f, l: l)\n",
    "print(ds_y)\n",
    "y_test_onehot = []\n",
    "for d in ds_y.batch(1):\n",
    "    for d1 in d:\n",
    "        y_test_onehot.append(d1.numpy())\n",
    "y_test = np.array([np.argmax(a, axis=1) for a in y_test_onehot]).flatten()\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run prediction on the dev dataset\n",
    "y_pred = model.predict(dataset_test_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, ..., 0, 0, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bool = np.argmax(y_pred, axis = 1)\n",
    "y_pred_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      3325\n",
      "           1       0.85      0.67      0.75      3331\n",
      "           2       0.71      0.88      0.78      3328\n",
      "\n",
      "    accuracy                           0.81      9984\n",
      "   macro avg       0.82      0.81      0.81      9984\n",
      "weighted avg       0.82      0.81      0.81      9984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_bool))\n",
    "#['NOT ENOUGH INFO', 'REFUTES', 'SUPPORTS'] == [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
