{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "printable-invalid",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "useful-posting",
   "metadata": {},
   "source": [
    "#### Evaluate the model on test dataset\n",
    "\n",
    "The test dataset will use predicted pages and predicted sentences. \n",
    "\n",
    "The predictions are generated via a seperate process in the our pipeline which must be executed before this step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-nutrition",
   "metadata": {},
   "source": [
    "#### Structure of the test dataset\n",
    "\n",
    "format: \n",
    "- id: id of the claim\n",
    "- label: the text label of the example (e.g. SUPPORTS, REFUTES or NOT ENOUGH INFO)\n",
    "- claim: the claim text\n",
    "- evidence: array of evidence groups\n",
    "- evidence group: [evidence id, N/A, Document Id, evidence tag, [array of closest sentences/lines, array of those line ids in the page]]\n",
    "\n",
    "We will need to read this data, format and extract the evidence, the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "packed-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mda.src.dataset.DatasetReader import DatasetReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-driving",
   "metadata": {},
   "source": [
    "#### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stuffed-given",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145449/145449 [00:01<00:00, 84174.33it/s]\n",
      "100%|██████████| 145449/145449 [00:01<00:00, 143689.73it/s]\n"
     ]
    }
   ],
   "source": [
    "infile = 'working/data/training/train.ns.pages.p5.jsonl'\n",
    "dsreader = DatasetReader(in_file=infile,label_checkpoint_file=None, database_path='data/data/fever/fever.db')\n",
    "raw, data = dsreader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inclusive-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = dsreader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "funded-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the label encoder\n",
    "import pickle\n",
    "with open('working/data/training/label_encoder_train.pkl', 'wb') as f:\n",
    "    pickle.dump(dsreader.labelencoder, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-reynolds",
   "metadata": {},
   "source": [
    "### Load test data\n",
    "Use the saved label encodings from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daily-portugal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:00<00:00, 17446.99it/s]\n",
      "100%|██████████| 9999/9999 [00:00<00:00, 137812.57it/s]\n"
     ]
    }
   ],
   "source": [
    "infile = 'working/data/training/paper_test_pipeline.ps.pages.p5.jsonl'\n",
    "label_checkpoint_file = 'working/data/training/label_encoder_train.pkl'\n",
    "dsreader = DatasetReader(in_file=infile,label_checkpoint_file=label_checkpoint_file, database_path='data/data/fever/fever.db', type='test')\n",
    "## read the raw and the formatted data\n",
    "raw_test, test_data = dsreader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "celtic-subsection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(2,), dtype=tf.string, name=None), TensorSpec(shape=(3,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "ds_test = dsreader.get_dataset()\n",
    "print(ds_test.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-kingston",
   "metadata": {},
   "source": [
    "#### Load the BERT tokenizer\n",
    "\n",
    "The FEVER vocab file is build using tokens that were concatenations of the train and the dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "provincial-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n",
    "import tensorflow_text as text\n",
    "bert_tokenizer_params=dict(lower_case=True)\n",
    "vocab_file_out = 'working/data/fever_vocab.txt'\n",
    "pt_tokenizer = text.BertTokenizer(vocab_file_out, **bert_tokenizer_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-accommodation",
   "metadata": {},
   "source": [
    "#### Prepare the tensor dataset for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "professional-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "christian-peter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (60,), types: tf.int64>\n",
      "<MapDataset shapes: (60,), types: tf.int64>\n",
      "<BatchDataset shapes: (((64, 60), (64, 60)), (64, 3)), types: ((tf.int64, tf.int64), tf.int32)>\n",
      "((TensorSpec(shape=(64, 60), dtype=tf.int64, name=None), TensorSpec(shape=(64, 60), dtype=tf.int64, name=None)), TensorSpec(shape=(64, 3), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "MAX_SEQ_LEN = 60\n",
    "BUFFER_SIZE = 32000\n",
    "def tokenize_and_pad(text, max_len):\n",
    "    segment = pt_tokenizer.tokenize(text).merge_dims(1, -1)\n",
    "    inp = segment.to_tensor(shape=[None, max_len])\n",
    "    return inp[0]\n",
    "\n",
    "h = ds_test.map(lambda x, y: tokenize_and_pad(x[0], MAX_SEQ_LEN))\n",
    "e = ds_test.map(lambda x, y: tokenize_and_pad(x[1], MAX_SEQ_LEN))\n",
    "l = ds_test.map(lambda x, y: y)\n",
    "print(h)\n",
    "print(e)\n",
    "f = tf.data.Dataset.zip((h,e))\n",
    "d = tf.data.Dataset.zip((f,l))\n",
    "# do not shuffle\n",
    "dataset_test = d.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset_test)\n",
    "print(dataset_test.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sixth-meditation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim_texts.jsonl  embedding_mappings_300d.npz    test_y_preds.npz  \u001b[0m\u001b[01;34mtraining\u001b[0m/\n",
      "\u001b[01;34mdev\u001b[0m/               fever_vocab.txt                test_y_tests.npz\n",
      "dev_labels.npz     matching_page_sentences.jsonl  train_labels.npz\n",
      "dev_x.npz          \u001b[01;34mout\u001b[0m/                           train_x.npz\n"
     ]
    }
   ],
   "source": [
    "ls working/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-gibson",
   "metadata": {},
   "source": [
    "#### Load the prefilled embedding matrix from glove 300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cathedral-moral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arr_0']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile = np.load(\"working/data/embedding_mappings_300d.npz\")\n",
    "npzfile.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affected-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = npzfile['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-holly",
   "metadata": {},
   "source": [
    "#### Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "skilled-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mda.src.model.esim import esim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spanish-hopkins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "hypothesis (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "evidence (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2400300     hypothesis[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    2400300     evidence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 300)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 300)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, None, 600)    1442400     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 600)    1442400     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, None, None)   0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, None, None)   0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, None)   0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None, None)   0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, None, 600)    0           lambda_1[0][0]                   \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, None, 600)    0           lambda[0][0]                     \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, None, 600)    0           bidirectional[0][0]              \n",
      "                                                                 dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, None, 600)    0           bidirectional[0][0]              \n",
      "                                                                 dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, None, 600)    0           bidirectional_1[0][0]            \n",
      "                                                                 dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, None, 600)    0           bidirectional_1[0][0]            \n",
      "                                                                 dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 2400)   0           bidirectional[0][0]              \n",
      "                                                                 dot_1[0][0]                      \n",
      "                                                                 subtract[0][0]                   \n",
      "                                                                 multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 2400)   0           bidirectional_1[0][0]            \n",
      "                                                                 dot_2[0][0]                      \n",
      "                                                                 subtract_1[0][0]                 \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Compresser (TimeDistributed)    (None, None, 300)    720300      concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 300)    0           Compresser[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 300)    0           Compresser[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "finaldecoder (Bidirectional)    (None, None, 600)    1442400     dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 600)          0           finaldecoder[0][0]               \n",
      "                                                                 finaldecoder[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 600)          0           finaldecoder[0][0]               \n",
      "                                                                 finaldecoder[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2400)         0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "                                                                 global_average_pooling1d[1][0]   \n",
      "                                                                 global_max_pooling1d[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2400)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense300_ (Dense)               (None, 100)          240100      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 100)          0           dense300_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "judge300_ (Dense)               (None, 3)            303         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,088,503\n",
      "Trainable params: 5,287,903\n",
      "Non-trainable params: 4,800,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "esim_model = esim(embedding_matrix=embedding_matrix, vocab_size = 8000, embedding_dim=300, alignment_dense_dim=300, final_dense_dim=100)\n",
    "model = esim_model.build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-boost",
   "metadata": {},
   "source": [
    "#### Check the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cloudy-tennessee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 25s 147ms/step - loss: 1.7892 - accuracy: 0.5669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7892426252365112, 0.5669070482254028]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_filepath = 'tmp/attention_esim/checkpoint_fever_rte_esim'\n",
    "model.load_weights(checkpoint_filepath)\n",
    "model.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-integration",
   "metadata": {},
   "source": [
    "#### Calculate the FEVER score\n",
    "\n",
    "- Strictly correct: when all the evidences predicted are correct and the predicted label is correct\n",
    "- Correct: when only the predicted label is correct "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-knitting",
   "metadata": {},
   "source": [
    "#### Compute the precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fifteen-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "backed-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred_proba, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "black-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'working/data/test_y_preds.npz'\n",
    "np.savez(outfile, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "industrial-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_y = dataset_test.map(lambda f, l: l)\n",
    "y_test_onehot = []\n",
    "for d in ds_y.batch(1):\n",
    "    for d1 in d:\n",
    "        y_test_onehot.append(d1.numpy())\n",
    "y_test = np.array([np.argmax(a, axis=1) for a in y_test_onehot]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "gross-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'working/data/test_y_tests.npz'\n",
    "np.savez(outfile, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "offensive-tourism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOT ENOUGH INFO', 'SUPPORTS', 'SUPPORTS', 'REFUTES']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d['label_text'] for d in test_data[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "structured-hopkins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.84      0.62      3328\n",
      "           1       0.74      0.32      0.45      3328\n",
      "           2       0.64      0.54      0.59      3328\n",
      "\n",
      "    accuracy                           0.57      9984\n",
      "   macro avg       0.62      0.57      0.55      9984\n",
      "weighted avg       0.62      0.57      0.55      9984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "#['NOT ENOUGH INFO', 'REFUTES', 'SUPPORTS'] == [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "gentle-acquisition",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": 113501, \"verifiable\": \"NOT VERIFIABLE\", \"label\": \"NOT ENOUGH INFO\", \"claim\": \"Grease had bad reviews.\", \"evidence\": [[[133128, null, \"Grease_gun_-LRB-tool-RRB-\", -1, [[\"Hand-powered , where there is no trigger mechanism , and the grease is forced through the aperture by the back-pressure built up by pushing on the butt of the grease gun , which slides a piston through the body of the tool , pumping grease out of the aperture .\"], []]], [-1, null, \"Grease_gun_-LRB-tool-RRB-\", -2, [[], []]], [-1, null, \"Nasal_sebum\", -2, [[], []]], [-1, null, \"Grease\", -2, [[], []]], [-1, null, \"Thermal_interface_material\", -2, [[], []]]]]}\n"
     ]
    }
   ],
   "source": [
    "!head -1 working/data/training/paper_test_pipeline.ps.pages.p5.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "adjacent-quick",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_dev.jsonl   shared_task_dev.jsonl   train.jsonl\n",
      "paper_test.jsonl  shared_task_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "ls /local/fever-common/data/fever-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-briefs",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "statistical-bowling",
   "metadata": {},
   "source": [
    "For <b>fever score</b>, we will need to compare the labels and the evidences.\n",
    "\n",
    "First we need to extract the true labels and evidences from the original training dataset.\n",
    "\n",
    "In the original dataset, we will need to sample data for the NEI class just like we did for our original training\n",
    "\n",
    "Note: the dataset root path should match what's in /loca/fever-common/ in the 'fever-common' container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incorrect-wagon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "industrial-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mda.src.dataset.DatasetGenerator import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "british-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_generator = DatasetGenerator(dataset_root='data/data/',out_dir='working/data/out/', database_path='data/data/fever/fever.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "yellow-combine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/9999 [00:00<02:49, 58.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory working/data/out/\n",
      "Writing data to working/data/out//paper_test.ns.pages.p5.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [02:47<00:00, 59.85it/s] \n"
     ]
    }
   ],
   "source": [
    "ds_generator.generate_nei_evidences('paper_test', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-broadcast",
   "metadata": {},
   "source": [
    "### In dataset type B\n",
    "\n",
    "We have predicted pages and predicted sentences per page for each claim. We need the predictions for those pages and sentences to compute the FEVER score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "scenic-origin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[133128,\n",
       "   None,\n",
       "   'Grease_gun_-LRB-tool-RRB-',\n",
       "   -1,\n",
       "   [['Hand-powered , where there is no trigger mechanism , and the grease is forced through the aperture by the back-pressure built up by pushing on the butt of the grease gun , which slides a piston through the body of the tool , pumping grease out of the aperture .'],\n",
       "    []]],\n",
       "  [-1, None, 'Grease_gun_-LRB-tool-RRB-', -2, [[], []]],\n",
       "  [-1, None, 'Nasal_sebum', -2, [[], []]],\n",
       "  [-1, None, 'Grease', -2, [[], []]],\n",
       "  [-1, None, 'Thermal_interface_material', -2, [[], []]]]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test[:1][0]['evidence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-classics",
   "metadata": {},
   "source": [
    "### In dataset type A\n",
    "\n",
    "We also need the original annotated pages and the sentences from the original file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "legendary-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "from mda.src.utils.readers import JSONLineReader\n",
    "from mda.src.utils.eval import *\n",
    "working_dir = 'working/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-burlington",
   "metadata": {},
   "source": [
    "Read the original / gold evidences from the test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cloudy-costa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:00<00:00, 179961.06it/s]\n"
     ]
    }
   ],
   "source": [
    "jlr = JSONLineReader()\n",
    "split = 'paper_test'\n",
    "k = 5\n",
    "test_data_file = working_dir + \"training/{0}.ns.pages.p{1}.jsonl\".format(split, k)\n",
    "data_orig = jlr.read(test_data_file)\n",
    "orig_evidences = [d['evidence'] for d in data_orig[:len(y_test)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-heart",
   "metadata": {},
   "source": [
    "Generate the final predictions, for the label, the predicted pages and the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "revolutionary-chapel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9984it [00:00, 80206.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to training/paper_test_predicted_pipeline.ps.pages.p5.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "split = 'paper_test_predicted'\n",
    "k = 5\n",
    "with open(working_dir + \"training/{0}_pipeline.ps.pages.p{1}.jsonl\".format(split,k),\"w+\") as f_out:\n",
    "    print(\"Saving to training/{0}_pipeline.ps.pages.p{1}.jsonl\".format(split,k))\n",
    "    for rec, orig, true_label, predicted_label in tqdm(zip(raw_test[:len(y_test)], orig_evidences, y_test, y_pred)):\n",
    "        evs = []\n",
    "        for evidence_group in rec['evidence']:\n",
    "            for evidence in evidence_group:\n",
    "                if evidence[0] > -1:\n",
    "                    ev = [evidence[0], evidence[1], evidence[2], evidence[4][1]]\n",
    "                    evs.append(ev)\n",
    "        out = {'true_label': str(true_label), 'predicted_label': str(predicted_label), 'orig': orig, 'pred': evs}\n",
    "        f_out.write(json.dumps(out) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "satellite-acrobat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"true_label\": \"0\", \"predicted_label\": \"0\", \"orig\": [[[133128, null, \"Grease_gun_-LRB-tool-RRB-\", -1]]], \"pred\": [[133128, null, \"Grease_gun_-LRB-tool-RRB-\", []]]}\n"
     ]
    }
   ],
   "source": [
    "!head -1 working/data/training/paper_test_predicted_pipeline.ps.pages.p5.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-shore",
   "metadata": {},
   "source": [
    "Load the predictions (we just made) from the file to use in fever scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "developed-trustee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9984/9984 [00:00<00:00, 15031.09it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_jsonl_data(filename):\n",
    "    jlr = JSONLineReader()\n",
    "    predicted_results = jlr.read(filename)\n",
    "    return predicted_results\n",
    "split = 'paper_test_predicted'\n",
    "k = 5\n",
    "filename = working_dir + \"training/{0}_pipeline.ps.pages.p{1}.jsonl\".format(split, k)\n",
    "predicted_results = read_jsonl_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "excessive-floating",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fever_score(predicted_results):\n",
    "    strictly_correct = 0\n",
    "    correct = 0\n",
    "    cnt = 0\n",
    "    for d in tqdm(predicted_results):\n",
    "        true_label = d['true_label']\n",
    "        predicted_label = d['predicted_label']\n",
    "        true_evidence = d['orig']\n",
    "        predicted_evidence = d['pred']\n",
    "        te = {}\n",
    "        pe = {}\n",
    "        #is correct?\n",
    "        if (true_label == predicted_label):\n",
    "            correct += 1\n",
    "            # is strictly correct?\n",
    "            if (true_label != '0') and (true_label==predicted_label):\n",
    "                for eg in true_evidence:\n",
    "                    for e in eg:\n",
    "                        if e[2] in te:\n",
    "                            te[e[2]].append(e[3])\n",
    "                        else:\n",
    "                            te[e[2]]= [e[3]]    \n",
    "\n",
    "                for e in predicted_evidence:\n",
    "                    if e[2] in pe:\n",
    "                        pe[e[2]].append(e[3])\n",
    "                    else:\n",
    "                        pe[e[2]]= [e[3]]\n",
    "\n",
    "                # for each annotated evidence, see if we predicted the evidences\n",
    "                # did we correctly predict all pages?\n",
    "                all_pages = all([k1 in pe.keys() for k1 in te.keys()])\n",
    "                if all_pages:\n",
    "                    #for the pages we predicted, did we predict all the sentences?\n",
    "                    for k in te.keys():\n",
    "                        if k in pe: # the page is predicted\n",
    "                            true_sents = np.unique(te[k])\n",
    "                            pre_sents = np.unique(pe[k][0])\n",
    "                            #if all the true sentences were predicted\n",
    "                            match = all([actual_sent in pre_sents for actual_sent in true_sents])\n",
    "                            #if match and (len(true_sents) == len(pre_sents)):\n",
    "                            #we are predicting 5 lines per page, so the count may not match with the true evidence lines\n",
    "                            if match:\n",
    "                                strictly_correct += 1\n",
    "            elif (true_label == '0') and (true_label == predicted_label): # not enough info\n",
    "                    strictly_correct += 1\n",
    "    noevscore = np.round(correct/len(predicted_results)*100,2)\n",
    "    score = np.round(strictly_correct/len(predicted_results)*100,2)\n",
    "    print(\"noevscore={}, score={}\".format(noevscore, score))\n",
    "    return noevscore, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "miniature-tower",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9984/9984 [00:00<00:00, 193731.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noevscore=56.69, score=35.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56.69, 35.43)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_fever_score(predicted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-canadian",
   "metadata": {},
   "source": [
    "#### From original FEVER paper\n",
    "Finally, we predict entailment\n",
    "using the Decomposable Attention model trained\n",
    "with the NEARESTP strategy. The classification\n",
    "accuracy is <b>31.87%</b>. Ignoring the requirement for\n",
    "correct evidence (NoScoreEv) the accuracy is\n",
    "<b>50.91%</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-marble",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
